{
 "cells": [
  {
   "cell_type": "code",
   "id": "4b82e32c11f0fc62",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:00.507592Z",
     "start_time": "2025-03-21T10:49:00.500058Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import color"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:00.517652Z",
     "start_time": "2025-03-21T10:49:00.509851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_harris_corners(image_path, output_path):\n",
    "    \"\"\"\n",
    "    对输入图像进行 Harris 角点检测，并在角点位置标记红色后保存结果\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_f = np.float32(gray)\n",
    "    harris_response = cv2.cornerHarris(gray_f, blockSize=2, ksize=3, k=0.04)\n",
    "    harris_response = cv2.dilate(harris_response, None)\n",
    "    img[harris_response > 0.01 * harris_response.max()] = [0, 0, 255]\n",
    "    cv2.imwrite(output_path, img)"
   ],
   "id": "ff595e7cbc255fa5",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:00.571364Z",
     "start_time": "2025-03-21T10:49:00.564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_sift_features(image_path):\n",
    "    \"\"\"\n",
    "    使用 SIFT 提取图像的关键点和描述子\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "    return keypoints, descriptors"
   ],
   "id": "e8503d6c63b03096",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:00.594966Z",
     "start_time": "2025-03-21T10:49:00.585254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_hog_features(image_path, patch_size=32):\n",
    "    \"\"\"\n",
    "    利用 Harris 算法检测角点，然后对每个角点周围提取固定大小（patch_size x patch_size）的图像块，\n",
    "    并计算 HOG 描述子，返回关键点（cv2.KeyPoint 列表）和描述子（numpy 数组）。\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    gray_f = np.float32(img)\n",
    "    harris_response = cv2.cornerHarris(gray_f, blockSize=2, ksize=3, k=0.04)\n",
    "    harris_response = cv2.dilate(harris_response, None)\n",
    "    threshold = 0.01 * harris_response.max()\n",
    "    # 获取角点坐标 (y, x)\n",
    "    coords = np.argwhere(harris_response > threshold)\n",
    "    \n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "    half = patch_size // 2\n",
    "    for (y, x) in coords:\n",
    "        # 确保图像块在图像内\n",
    "        if x - half < 0 or x + half >= img.shape[1] or y - half < 0 or y + half >= img.shape[0]:\n",
    "            continue\n",
    "        patch = img[y-half:y+half, x-half:x+half]\n",
    "        hog_desc = hog(patch, pixels_per_cell=(8,8), cells_per_block=(2,2), feature_vector=True)\n",
    "        descriptors.append(hog_desc)\n",
    "        # 转换 x,y 为 float 类型构造 cv2.KeyPoint 对象\n",
    "        keypoints.append(cv2.KeyPoint(float(x), float(y), patch_size))\n",
    "    \n",
    "    if len(descriptors) == 0:\n",
    "        descriptors = None\n",
    "    else:\n",
    "        descriptors = np.array(descriptors, dtype=np.float32)\n",
    "        # 如果只有一个角点，则确保 descriptors 为二维数组\n",
    "        if descriptors.ndim == 1:\n",
    "            descriptors = descriptors[np.newaxis, :]\n",
    "    return keypoints, descriptors\n",
    "\n"
   ],
   "id": "fb36985aa81a6ab2",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:00.606172Z",
     "start_time": "2025-03-21T10:49:00.599468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def match_features(desc1, desc2):\n",
    "    \"\"\"\n",
    "    使用暴力匹配器对两组描述子进行匹配，并返回按距离排序的匹配结果\n",
    "    \"\"\"\n",
    "    # 确保 descriptor 为连续的 numpy 数组\n",
    "    desc1 = np.ascontiguousarray(desc1, dtype=np.float32)\n",
    "    desc2 = np.ascontiguousarray(desc2, dtype=np.float32)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = bf.match(desc1, desc2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    return matches"
   ],
   "id": "f4713a5864c1b4d4",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:00.642582Z",
     "start_time": "2025-03-21T10:49:00.634090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_and_match_features(img1_path, img2_path, method, match_output_path):\n",
    "    \"\"\"\n",
    "    根据所选描述子类型（SIFT 或 HOG），提取图像的关键点与描述子，然后匹配，\n",
    "    并将匹配结果绘制后保存到指定路径。\n",
    "    \"\"\"\n",
    "    if method.upper() == \"SIFT\":\n",
    "        kp1, desc1 = extract_sift_features(img1_path)\n",
    "        kp2, desc2 = extract_sift_features(img2_path)\n",
    "    elif method.upper() == \"HOG\":\n",
    "        kp1, desc1 = extract_hog_features(img1_path)\n",
    "        kp2, desc2 = extract_hog_features(img2_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Please use 'SIFT' or 'HOG'.\")\n",
    "    \n",
    "    if desc1 is None or desc2 is None or len(kp1) == 0 or len(kp2) == 0:\n",
    "        raise ValueError(\"No descriptors found in one of the images.\")\n",
    "    \n",
    "    matches = match_features(desc1, desc2)\n",
    "    \n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "    img_matches = cv2.drawMatches(img1, kp1, img2, kp2, matches[:50], None, flags=2)\n",
    "    cv2.imwrite(match_output_path, img_matches)"
   ],
   "id": "b65387f8183136e",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:00.664068Z",
     "start_time": "2025-03-21T10:49:00.653830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stitch_images(img1_path, img2_path, method, output_path):\n",
    "    \"\"\"\n",
    "    根据 method (\"SIFT\" 或 \"HOG\") 提取匹配关键点，并利用 RANSAC 求解仿射变换矩阵，\n",
    "    将第二幅图像变换后与第一幅图像叠加，简单拼接后保存结果。\n",
    "    \"\"\"\n",
    "    if method.upper() == \"SIFT\":\n",
    "        kp1, desc1 = extract_sift_features(img1_path)\n",
    "        kp2, desc2 = extract_sift_features(img2_path)\n",
    "    elif method.upper() == \"HOG\":\n",
    "        kp1, desc1 = extract_hog_features(img1_path)\n",
    "        kp2, desc2 = extract_hog_features(img2_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Please use 'SIFT' or 'HOG'.\")\n",
    "    \n",
    "    if desc1 is None or desc2 is None or len(kp1) == 0 or len(kp2) == 0:\n",
    "        raise ValueError(\"No descriptors found in one of the images.\")\n",
    "    \n",
    "    matches = match_features(desc1, desc2)\n",
    "    if len(matches) < 3:\n",
    "        raise ValueError(\"Not enough matches to compute transformation.\")\n",
    "    \n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    \n",
    "    # 使用 RANSAC 计算仿射变换矩阵\n",
    "    M, mask = cv2.estimateAffinePartial2D(src_pts, dst_pts, method=cv2.RANSAC)\n",
    "    \n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "    h2, w2 = img2.shape[:2]\n",
    "    img2_transformed = cv2.warpAffine(img2, M, (w2, h2))\n",
    "    \n",
    "    # 简单叠加方式进行拼接（实际应用中可采用更复杂的融合策略）  \n",
    "    panorama = np.maximum(img1, img2_transformed)\n",
    "    cv2.imwrite(output_path, panorama)\n"
   ],
   "id": "388fb2e471bcd153",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:00.678954Z",
     "start_time": "2025-03-21T10:49:00.672174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stitch_multiple_images(image_paths, output_path):\n",
    "    \"\"\"\n",
    "    基于 SIFT + RANSAC 的方法，依次对多幅图像进行拼接，\n",
    "    最终将拼接结果保存到 output_path 中。\n",
    "    \"\"\"\n",
    "    result = cv2.imread(image_paths[0])\n",
    "    result_path = \"temp_panorama.png\"\n",
    "    cv2.imwrite(result_path, result)\n",
    "    for i in range(1, len(image_paths)):\n",
    "        stitch_images(result_path, image_paths[i], \"SIFT\", result_path)\n",
    "        result = cv2.imread(result_path)\n",
    "    cv2.imwrite(output_path, result)\n"
   ],
   "id": "3fefd32a636c766e",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:00.734518Z",
     "start_time": "2025-03-21T10:49:00.691292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 检测角点\n",
    "detect_harris_corners(\"images/sudoku.png\", \"results/sudoku_keypoints.png\")"
   ],
   "id": "1a4192e2b256e926",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:00.962986Z",
     "start_time": "2025-03-21T10:49:00.735533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 提取 SIFT 特征\n",
    "extract_and_match_features(\"images/uttower1.jpg\", \"images/uttower2.jpg\", \"SIFT\", \"results/uttower_match_sift.png\")"
   ],
   "id": "d7c4754e09cfc156",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:21.830349Z",
     "start_time": "2025-03-21T10:49:00.964010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 提取 HOG 特征\n",
    "extract_and_match_features(\"images/uttower1.jpg\", \"images/uttower2.jpg\", \"HOG\", \"results/uttower_match_hog.png\")"
   ],
   "id": "83ff00e705ccdca6",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:42.743464Z",
     "start_time": "2025-03-21T10:49:21.831931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 拼接两张图像\n",
    "stitch_images(\"images/uttower1.jpg\", \"images/uttower2.jpg\", \"SIFT\", \"results/uttower_stitching_sift.png\")\n",
    "stitch_images(\"images/uttower1.jpg\", \"images/uttower2.jpg\", \"HOG\", \"results/uttower_stitching_hog.png\")"
   ],
   "id": "3f826650ab5dc4c8",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:43.672467Z",
     "start_time": "2025-03-21T10:49:42.743464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 拼接多张图像\n",
    "stitch_multiple_images([\"images/yosemite1.jpg\", \"images/yosemite2.jpg\", \"images/yosemite3.jpg\", \"images/yosemite4.jpg\"], \"results/yosemite_stitching.png\")"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T10:49:43.678146Z",
     "start_time": "2025-03-21T10:49:43.673609Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a136d348b404132a",
   "outputs": [],
   "execution_count": 94
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
